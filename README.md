## íŒŒì´ì¬ìœ¼ë¡œ í•´ë³´ëŠ” Spark í”„ë¡œê·¸ë˜ë°

Pysparkì„ ì‚¬ìš©í•˜ë©° ì‹¤ìŠµ í™˜ê²½ì€ Google Colab ì…ë‹ˆë‹¤. ëª‡ê°œì˜ exampleì€ Spark Web UIë¥¼ í™œìš©í•´ Execution Planì„ í™•ì¸í•˜ê¸°ìœ„í•´ localì—ì„œ Spark standalone ëª¨ë“œë¥¼ ì„¤ì¹˜í•˜ì—¬ ì§„í–‰ í•˜ì˜€ìŠµë‹ˆë‹¤.   

---
<br/>

# **Advanced Spark Features: Learning and Exploration**

This repository is dedicated to understanding and experimenting with advanced features of **Apache Spark**, focusing on data engineering and machine learning use cases. The aim is to explore practical applications of Spark's capabilities and best practices for scalable data processing.

---

## **ğŸ“š Learning Objectives**

1. **Understand Spark's Core Components**
   - SparkSQL for querying and managing structured data.
   - PySpark for building ETL pipelines and data transformations.
   - SparkML for applying machine learning algorithms.

2. **Explore Advanced Spark Features**
   - **Bucketing**: Optimize joins and aggregations by reducing shuffle overhead.
   - **Partitioning**: Organize data efficiently to improve query performance.
   - **UDFs (User-Defined Functions)**: Write custom functions for advanced transformations.
   - **Schema Evolution**: Handle dynamic schema changes in datasets.
   - **Broadcast Joins**: Optimize small-to-large table joins.

3. **Integrate Hive Metastore**
   - Manage schema and metadata effectively for structured data.

4. **Learn Testing Practices**
   - Validate ETL pipelines and UDFs using unittest frameworks.

---

## **ğŸš€ Features Explored**

### **1. Bucketing and Partitioning**
- Implemented bucketing to optimize shuffle operations during joins.
- Used partitioning to organize large datasets by keys (e.g., date, region) for faster filtering.

### **2. Custom Transformations with UDFs**
- Developed and tested user-defined functions to handle complex logic.

### **3. Broadcast Joins**
- Leveraged broadcast joins to reduce shuffle for small datasets.

### **4. Schema Evolution**
- Managed schema changes dynamically for Parquet/ORC files to handle evolving datasets.

### **5. Integration with Hive Metastore**
- Used Hive Metastore for schema and metadata management to query tables seamlessly with SparkSQL.
